---
title: "Tutorial"
output: 
  learnr::tutorial:
    progressive: true
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(learnr)
library(tidyverse)
library(DBI)
library(rvest)
library(janitor)
library(here)
library(glue)
library(esquisse)
library(performance)
library(plotly)
```

# Drag Race 

One Friday night I was enjoying my favorite ritual, watching the latest episode of RuPaul's Drag Race and enjoying a bubbly beverage with some friends.

![](https://i.pinimg.com/originals/9f/93/0f/9f930fc91e3f87d640f842ae6e0dde00.gif)

Someone suggested the current season wasn't "as good as" one of its predecessors. Well, let me tell you.... that got my data science brain going. First thought, how can they make this bold statement without data?

![](https://64.media.tumblr.com/97c859fda24580750ba32e59e0cf5ef2/tumblr_inline_p7fxplJCk91qz7j5g_250.gifv){width="252"}

Now, let me be very clear- each season the queens BRING IT and dazzle us with their talent. This is not a commentary on the Queen's, rather the production and marketing of a season.

I'm a Data Scientist who used to build databases in a past life as a Data Engineer, and knew I could find it on the internet, [Wiki Rule of the internet](https://tvtropes.org/pmwiki/pmwiki.php/Main/TheWikiRule), and build a pipeline to collect it.

With no intention of submitting this to an academic article... off to Wikipedia I went! Sorry, every educator I've ever had. I've been watching the competition for a while and had a hunch that the seasons that aired on VH1, season 9 - current, would be my best bet. Lucky for me, this was true. Each of the pages had a table containing the Neilson rating and viewer count, in millions, for each episode.

I had two options:

1.  Use the [datapasta library](https://github.com/MilesMcBain/datapasta) to paste the 6 tables into a tribble and bind them together

2.  Scrape each page for this table

    -   The only difference in the URLs was the season number

I'm lazy, and knew I would get sick and tired of copy paste, no shade to datapasta! The following sections of this document will walk you through 4 main points:

1.  How to scrape a table from Wikipedia (**Extract**)

2.  Simple data cleaning and restructuring (**Transform**)

3.  Quick way to store things in a central location (Load)

4.  Use the results from steps 1-3 to answer the question, "Is there a difference in the average rating of a season?

## Extract

### Wiki.tables 

I am going to assume knowledge of basic HTML

Write the R code required to add two plus two:

```{r get_the_table_from_one_page, exercise=TRUE}

season_9_df <- tribble(~wiki_url,"https://en.wikipedia.org/wiki/RuPaul%27s_Drag_Race_(season_9)")%>%
  mutate(
          all_tables=  map(wiki_url, 
                             ~ { 
                                 # .x is the dataframe piped in 
                                 # and for each row of the frame the 
                                 # chain of functions is executed 
                                 # a cleaner way of getthing things 
                                 # than going down the loop route
                                 .x %>% 
                                   read_html(wiki_url) %>% 
                                   html_nodes("table.wikitable") %>% 
                                   html_table(header=TRUE)  
                                }
                            )
        ) %>% 
  unnest(all_tables) %>% 
  mutate(table_column_names=map(all_tables,
                                  ~{.x %>% 
                                      names()
                                    }
                                )
    
  ) %>% 
  filter(str_detect(table_column_names,"View")
         ) %>% 
  select(all_tables) %>% 
  unnest(all_tables)

season_9_df
```
